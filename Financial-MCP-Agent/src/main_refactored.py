"""
é‡‘èåˆ†ææ™ºèƒ½ä½“ç³»ç»Ÿ - æ ¸å¿ƒå·¥ä½œæµæ¨¡å— (é‡æ„ç‰ˆ)

æœ¬æ–‡ä»¶åŒ…å«é‡‘èåˆ†ææ™ºèƒ½ä½“ç³»ç»Ÿçš„æ ¸å¿ƒæ‰§è¡Œé€»è¾‘ï¼Œè¢«é‡æ„ä¸ºä¸€ä¸ªå¯è°ƒç”¨çš„å¼‚æ­¥å‡½æ•°ï¼Œ
ä»¥ä¾¿äºè¢«ä¸åŒçš„å‰ç«¯ï¼ˆå¦‚å‘½ä»¤è¡Œã€Streamlitç•Œé¢ï¼‰è°ƒç”¨ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
- æ¥æ”¶ç”¨æˆ·æŸ¥è¯¢
- æ„å»ºå¹¶æ‰§è¡ŒLangGraphå¤šæ™ºèƒ½ä½“å·¥ä½œæµ
- è¿”å›ç»“æ„åŒ–çš„åˆ†æç»“æœ
"""

# ============================================================================
# å¯¼å…¥å¿…è¦çš„æ¨¡å—å’Œä¾èµ–
# ============================================================================

import os
import sys
import logging
import re
import asyncio
from datetime import datetime
from dotenv import load_dotenv
from langgraph.graph import StateGraph, END

# ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œï¼Œä»¥ä¾¿æ­£ç¡®å¯¼å…¥æ¨¡å—
# å¦‚æœä½ çš„ç›®å½•ç»“æ„æ˜¯ project/main.py, project/agents/...
# é‚£ä¹ˆè¿™ä¸ªè·¯å¾„è®¾ç½®æ˜¯æ­£ç¡®çš„
sys.path.insert(0, os.path.abspath(os.path.dirname(__file__)))

# è®¾ç½®ç¯å¢ƒå˜é‡æ¥æŠ‘åˆ¶transformerså’Œå…¶ä»–åº“çš„å†—ä½™è¾“å‡º
os.environ["TRANSFORMERS_VERBOSITY"] = "error"
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# æŠ‘åˆ¶éƒ¨åˆ†åº“çš„æ—¥å¿—è¾“å‡º
logging.getLogger("transformers").setLevel(logging.ERROR)
logging.getLogger("accelerate").setLevel(logging.ERROR)
logging.getLogger("torch").setLevel(logging.ERROR)
logging.getLogger("huggingface_hub").setLevel(logging.ERROR)
logging.getLogger("requests").setLevel(logging.ERROR)
logging.getLogger("urllib3").setLevel(logging.ERROR)

# é¡¹ç›®å†…éƒ¨æ¨¡å—å¯¼å…¥
# æ³¨æ„ï¼šè¯·ç¡®ä¿è¿™äº›æ¨¡å—è·¯å¾„æ˜¯æ­£ç¡®çš„
try:
    from utils.logging_config import setup_logger, SUCCESS_ICON, ERROR_ICON
    from utils.state_definition import AgentState
    from utils.execution_logger import initialize_execution_logger, finalize_execution_logger
    from agents.summary_agent import summary_agent
    from agents.value_agent import value_agent
    from agents.technical_agent import technical_agent
    from agents.fundamental_agent import fundamental_agent
    from agents.news_agent import news_agent
except ImportError as e:
    print(f"æ¨¡å—å¯¼å…¥é”™è¯¯: {e}")
    print("è¯·ç¡®ä¿ä½ åœ¨é¡¹ç›®çš„æ ¹ç›®å½•ä¸‹è¿è¡Œï¼Œå¹¶ä¸”æ‰€æœ‰ä¾èµ–éƒ½å·²å®‰è£…ã€‚")
    sys.exit(1)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv(override=True)

# è®¾ç½®æ—¥å¿—è®°å½•å™¨
logger = setup_logger(__name__)


# ============================================================================
# æ ¸å¿ƒå·¥ä½œæµå‡½æ•°
# ============================================================================

async def run_analysis_workflow(user_query: str, status_callback=None):
    """
    æ‰§è¡Œé‡‘èåˆ†æå·¥ä½œæµçš„æ ¸å¿ƒé€»è¾‘ã€‚

    :param user_query: ç”¨æˆ·çš„æŸ¥è¯¢å­—ç¬¦ä¸²ã€‚
    :param status_callback: ä¸€ä¸ªå¯é€‰çš„å›è°ƒå‡½æ•°ï¼Œç”¨äºå‘UIå‘é€çŠ¶æ€æ›´æ–°ã€‚
    :return: ä¸€ä¸ªåŒ…å«æœ€ç»ˆæŠ¥å‘Šå’Œè·¯å¾„çš„å­—å…¸ã€‚
    """
    
    def update_status(message: str):
        """å®‰å…¨åœ°è°ƒç”¨çŠ¶æ€å›è°ƒå‡½æ•°"""
        logger.info(message)
        if status_callback:
            try:
                status_callback(message)
            except Exception as e:
                logger.warning(f"è°ƒç”¨çŠ¶æ€å›è°ƒå‡½æ•°æ—¶å‡ºé”™: {e}")

    execution_logger = initialize_execution_logger()
    update_status(f"âœ… æ‰§è¡Œæ—¥å¿—ç³»ç»Ÿå·²åˆå§‹åŒ–ï¼Œç›®å½•: {execution_logger.execution_dir}")

    try:
        # 1. å®šä¹‰LangGraphå·¥ä½œæµ
        workflow = StateGraph(AgentState)
        workflow.add_node("start_node", lambda state: state)
        workflow.add_node("fundamental_analyst", fundamental_agent)
        workflow.add_node("technical_analyst", technical_agent)
        workflow.add_node("value_analyst", value_agent)
        workflow.add_node("news_analyst", news_agent)
        workflow.add_node("summarizer", summary_agent)
        workflow.set_entry_point("start_node")
        workflow.add_edge("start_node", "fundamental_analyst")
        workflow.add_edge("start_node", "technical_analyst")
        workflow.add_edge("start_node", "value_analyst")
        workflow.add_edge("start_node", "news_analyst")
        workflow.add_edge("fundamental_analyst", "summarizer")
        workflow.add_edge("technical_analyst", "summarizer")
        workflow.add_edge("value_analyst", "summarizer")
        workflow.add_edge("news_analyst", "summarizer")
        workflow.add_edge("summarizer", END)
        app = workflow.compile()
        update_status("âœ… LangGraph å·¥ä½œæµæ„å»ºå®Œæˆã€‚")

        # 2. è‡ªç„¶è¯­è¨€å¤„ç†å’Œè‚¡ç¥¨ä¿¡æ¯æå–
        # (å°†åŸå§‹æ–‡ä»¶ä¸­çš„ extract_stock_info å‡½æ•°å®Œæ•´åœ°å¤åˆ¶åˆ°è¿™é‡Œ)
        def extract_stock_info(query):
            """ç²¾ç¡®æå–è‚¡ç¥¨ä»£ç å’Œå…¬å¸åç§°"""
            stock_code = None
            company_name = None
            patterns = [
                r'è¯·å¸®æˆ‘åˆ†æä¸€ä¸‹\s*([^ï¼ˆ(]+?)\s*[ï¼ˆ(](\d{5,6})[)ï¼‰]',
                r'åˆ†æä¸€ä¸‹\s*([^ï¼ˆ(]+?)\s*[ï¼ˆ(](\d{5,6})[)ï¼‰]',
                r'åˆ†æ\s*([^ï¼ˆ(]+?)\s*[ï¼ˆ(](\d{5,6})[)ï¼‰]',
                r'åˆ†æ\s*[ï¼ˆ(](\d{5,6})[)ï¼‰]\s*([^ï¼‰)]+)',
                r'å¸®æˆ‘çœ‹çœ‹\s*[ï¼ˆ(](\d{5,6})[)ï¼‰]\s*([^ï¼‰)]+?)(?:\s*è¿™åª|\s*è¿™ä¸ª)?\s*è‚¡ç¥¨',
                r'æˆ‘æƒ³äº†è§£ä¸€ä¸‹\s*([^ï¼ˆ(]+?)\s*[ï¼ˆ(](\d{5,6})[)ï¼‰]',
                r'å¸®æˆ‘çœ‹çœ‹\s*([^ï¼ˆ(]+?)\s*[ï¼ˆ(](\d{5,6})[)ï¼‰]',
                r'^([^ï¼ˆ(]+?)\s*[ï¼ˆ(](\d{5,6})[)ï¼‰]'
            ]
            for pattern in patterns:
                match = re.search(pattern, query)
                if match:
                    if len(match.groups()) == 2:
                        if match.group(1).isdigit():
                            stock_code, company_name = match.group(1), match.group(2).strip()
                        else:
                            company_name, stock_code = match.group(1).strip(), match.group(2)
                        return company_name, stock_code
            
            # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°å¸¦æ‹¬å·çš„ç»„åˆï¼Œåˆ™åˆ†åˆ«åŒ¹é…å…¬å¸åå’Œä»£ç 
            # ä¼˜å…ˆåŒ¹é…ä»£ç 
            code_match = re.search(r'\b(\d{5,6})\b', query)
            if code_match:
                stock_code = code_match.group(1)

            # åŒ¹é…å…¬å¸åç§° (æ›´é€šç”¨çš„æ¨¡å¼)
            name_patterns = [
                r'åˆ†æ(?:ä¸€ä¸‹)?\s*([^0-9ï¼ˆï¼‰()\s]+)',
                r'([^0-9ï¼ˆï¼‰()\s]+)\s*(?:è¿™åª|è¿™ä¸ª|çš„)?\s*è‚¡ç¥¨',
                r'(?:äº†è§£|çœ‹çœ‹|ç»™æˆ‘åˆ†æ)ä¸€ä¸‹\s*([^0-9ï¼ˆï¼‰()\s]+)',
                r'([^0-9ï¼ˆï¼‰()\s]+?)\s*çš„\s*(?:è´¢åŠ¡|ä¼°å€¼|é£é™©|ä»·å€¼|åŸºæœ¬é¢)',
            ]
            for pattern in name_patterns:
                name_match = re.search(pattern, query)
                if name_match:
                    potential_name = name_match.group(1).strip()
                    # é¿å…åŒ¹é…åˆ° "è‚¡ç¥¨" "ä»·å€¼" ç­‰è¯
                    if len(potential_name) >= 2 and potential_name not in ["è‚¡ç¥¨", "ä»·å€¼", "å…¬å¸"]:
                         company_name = potential_name
                         break # æ‰¾åˆ°ä¸€ä¸ªå°±åœæ­¢

            if company_name:
                stop_words = ['çš„', 'è¿™ä¸ª', 'è¿™åª', 'ä¸€ä¸‹', 'çœ‹çœ‹', 'äº†è§£', 'åˆ†æ', 'å¸®æˆ‘', 'æˆ‘æƒ³', 'ç»™æˆ‘']
                for word in stop_words:
                    company_name = company_name.replace(word, '').strip()
                if len(company_name) < 2: company_name = None

            return company_name, stock_code

        company_name, stock_code = extract_stock_info(user_query)
        update_status(f"ğŸ” ä»æŸ¥è¯¢ä¸­æå–åˆ°ä¿¡æ¯ - å…¬å¸: {company_name or 'æœªè¯†åˆ«'}, ä»£ç : {stock_code or 'æœªè¯†åˆ«'}")

        # 3. æ—¶é—´ä¿¡æ¯å¤„ç†
        current_datetime = datetime.now()
        current_date_en = current_datetime.strftime("%Y-%m-%d")

        # 4. å‡†å¤‡åˆå§‹çŠ¶æ€æ•°æ®
        initial_data = {
            "query": user_query,
            "current_date": current_date_en,
            "analysis_timestamp": current_datetime.isoformat()
        }
        if company_name:
            initial_data["company_name"] = company_name
        if stock_code:
            if stock_code.startswith('6'):
                initial_data["stock_code"] = f"sh.{stock_code}"
            elif stock_code.startswith(('0', '3')):
                initial_data["stock_code"] = f"sz.{stock_code}"
            else:
                initial_data["stock_code"] = stock_code
        
        if not company_name and not stock_code:
            raise ValueError("æ— æ³•ä»æ‚¨çš„æŸ¥è¯¢ä¸­è¯†åˆ«å‡ºæœ‰æ•ˆçš„å…¬å¸åç§°æˆ–è‚¡ç¥¨ä»£ç ï¼Œè¯·æä¾›æ›´æ˜ç¡®çš„ä¿¡æ¯ã€‚")

        initial_state = AgentState(messages=[], data=initial_data, metadata={})

        # 5. æ‰§è¡Œå·¥ä½œæµ
        update_status("\nğŸš€ **å¼€å§‹æ‰§è¡Œåˆ†æä»»åŠ¡...**")
        update_status("   - ğŸ“Š åŸºæœ¬é¢åˆ†æ Agent å¯åŠ¨...")
        update_status("   - ğŸ“ˆ æŠ€æœ¯é¢åˆ†æ Agent å¯åŠ¨...")
        update_status("   - ğŸ’° ä¼°å€¼åˆ†æ Agent å¯åŠ¨...")
        update_status("   - ğŸ“° æ–°é—»åˆ†æ Agent å¯åŠ¨...")
        update_status("\n*åˆ†æè¿‡ç¨‹å¯èƒ½éœ€è¦1-2åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...*")

        final_state = await app.ainvoke(initial_state)
        update_status("\nâœ… **æ‰€æœ‰åˆ†ææ¨¡å—æ‰§è¡Œå®Œæ¯•ï¼**")
        update_status("   - ğŸ¤– æ€»ç»“ Agent æ­£åœ¨æ•´åˆæŠ¥å‘Š...")

        # 6. ç»“æœå¤„ç†å’ŒæŠ¥å‘Šç”Ÿæˆ
        if final_state and final_state.get("data") and "final_report" in final_state["data"]:
            report_path = final_state['data'].get('report_path')
            execution_logger.log_final_report(final_state["data"]["final_report"], report_path)
            finalize_execution_logger(success=True)
            update_status(f"ğŸ‰ **æŠ¥å‘Šç”ŸæˆæˆåŠŸï¼**")
            
            return {
                "success": True,
                "report": final_state["data"]["final_report"],
                "report_path": report_path,
                "log_dir": execution_logger.execution_dir
            }
        else:
            raise RuntimeError("å·¥ä½œæµæ‰§è¡Œå®Œæ¯•ï¼Œä½†æœªèƒ½ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šã€‚")

    except Exception as e:
        logger.error(f"å·¥ä½œæµæ‰§è¡ŒæœŸé—´å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
        finalize_execution_logger(success=False, error=str(e))
        update_status(f"âŒ **å‘ç”Ÿé”™è¯¯**: {e}")
        return {
            "success": False,
            "error": "å·¥ä½œæµæ‰§è¡ŒæœŸé—´å‘ç”Ÿé”™è¯¯ã€‚",
            "details": str(e),
            "log_dir": execution_logger.execution_dir,
        }

# ============================================================================
# ç¨‹åºå…¥å£ç‚¹ (ç”¨äºç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶è¿›è¡Œæµ‹è¯•)
# ============================================================================
async def cli_main():
    """ä¿ç•™åŸå§‹çš„å‘½ä»¤è¡Œäº¤äº’åŠŸèƒ½ï¼Œç”¨äºæµ‹è¯•ã€‚"""
    print("é‡‘èåˆ†ææ™ºèƒ½ä½“ç³»ç»Ÿ - å‘½ä»¤è¡Œæµ‹è¯•æ¨¡å¼")
    user_query = input("ğŸ’¬ è¯·è¾“å…¥æ‚¨çš„åˆ†æéœ€æ±‚: ")
    if not user_query.strip():
        print("è¾“å…¥ä¸èƒ½ä¸ºç©ºï¼")
        return

    def cli_status_callback(message: str):
        """å‘½ä»¤è¡Œç‰ˆæœ¬çš„çŠ¶æ€å›è°ƒå‡½æ•°"""
        print(message.replace('**', '')) # ç§»é™¤Markdownæ ‡è®°

    result = await run_analysis_workflow(user_query, cli_status_callback)

    if result["success"]:
        print("\n--- æœ€ç»ˆåˆ†ææŠ¥å‘Š ---")
        print(result["report"])
        if result["report_path"]:
            print(f"\næŠ¥å‘Šå·²ä¿å­˜åˆ°: {result['report_path']}")
        print(f"æ‰§è¡Œæ—¥å¿—å·²ä¿å­˜åˆ°: {result['log_dir']}")
    else:
        print(f"\nåˆ†æå¤±è´¥: {result['error']}")
        print(f"è¯¦æƒ…: {result['details']}")
        print(f"é”™è¯¯æ—¥å¿—å·²ä¿å­˜åˆ°: {result['log_dir']}")

if __name__ == "__main__":
    # å¦‚æœç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶ï¼Œåˆ™è¿›å…¥å‘½ä»¤è¡Œæµ‹è¯•æ¨¡å¼
    # è¦è¿è¡ŒUIç•Œé¢ï¼Œè¯·è¿è¡Œ `streamlit run app.py`
    try:
        asyncio.run(cli_main())
    except KeyboardInterrupt:
        print("\nç¨‹åºå·²ç»ˆæ­¢ã€‚")

